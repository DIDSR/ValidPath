<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ML Assessment &mdash; ValidPath 2.0.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Annotation File Generator" href="ann_generator.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> ValidPath
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Home</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="inputrequirements.html">Data (Input/Output) Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="WSI.html">WSI Handler</a></li>
<li class="toctree-l1"><a class="reference internal" href="annotation.html">Annotation Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="patch.html">Patch Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="ann_generator.html">Annotation File Generator</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ML Assessment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-assessment.uncertainty">assessment.uncertainty module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.Delong_CI"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.Delong_CI()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.auc_keras_"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.auc_keras_()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.bootstrapping"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.bootstrapping()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.calc_pvalue"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.calc_pvalue()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.ci_"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.ci_()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.compute_ground_truth_statistics"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.compute_ground_truth_statistics()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.compute_midrank"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.compute_midrank()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.compute_midrank_weight"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.compute_midrank_weight()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.delong_roc_variance"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.delong_roc_variance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.fastDeLong"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.fastDeLong()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.fastDeLong_no_weights"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.fastDeLong_no_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.fastDeLong_weights"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.fastDeLong_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessment.uncertainty.Uncertainty_Analysis.get_report"><code class="docutils literal notranslate"><span class="pre">Uncertainty_Analysis.get_report()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#about-this-module">About this module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-required-packages">Loading Required Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generate-results">Generate Results</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ValidPath</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">ML Assessment</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/assessment.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ml-assessment">
<h1>ML Assessment<a class="headerlink" href="#ml-assessment" title="Permalink to this heading"></a></h1>
<section id="module-assessment.uncertainty">
<span id="assessment-uncertainty-module"></span><h2>assessment.uncertainty module<a class="headerlink" href="#module-assessment.uncertainty" title="Permalink to this heading"></a></h2>
<hr class="docutils" />
<p><strong>Title:</strong>        ValidPath Toolbox - Uncertainty Analysis module</p>
<p><strong>Description:</strong>  This is the Uncertainty Analysis module of the ValidPath toolbox. It is includes Uncertainty_Analysis class and several methods</p>
<p><strong>Classes:</strong>      Uncertainty_Analysis</p>
<p><strong>Methods:</strong>      get_report, <a href="#id1"><span class="problematic" id="id2">auc_keras_</span></a>, <a href="#id3"><span class="problematic" id="id4">ci_</span></a>, Delong_CI, compute_midrank, compute_midrank_weight, calc_pvalue, compute_ground_truth_statistics, delong_roc_variance, bootstrapping</p>
<hr class="docutils" />
<dl class="py class">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">assessment.uncertainty.</span></span><span class="sig-name descname"><span class="pre">Uncertainty_Analysis</span></span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.Delong_CI">
<span class="sig-name descname"><span class="pre">Delong_CI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_truth</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.Delong_CI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.Delong_CI" title="Permalink to this definition"></a></dt>
<dd><p>A Python implementation of an algorithm for computing the statistical significance of comparing two sets of predictions by ROC AUC. 
Also can compute variance of a single ROC AUC estimate. X. Sun and W. Xu, “Fast Implementation of DeLong’s Algorithm for Comparing the 
Areas Under Correlated Receiver Operating Characteristic Curves,” in IEEE Signal Processing Letters, vol. 21, no. 11, pp. 1389-1393, Nov. 2014, 
doi: 10.1109/LSP.2014.2337313.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>y_truth: ground_truth -  np.array of 0 and 1
y_pred:  predictions - np.array of floats of the probability of being class 1</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>auc, ci, lower_upper_q, auc_cov, auc_std</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.auc_keras_">
<span class="sig-name descname"><span class="pre">auc_keras_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fpr_keras</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tpr_keras</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.auc_keras_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.auc_keras_" title="Permalink to this definition"></a></dt>
<dd><p>Estimates confidence interval for Bernoulli p</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>fpr_keras: False Positive Rate Values
tpr_keras: True Positive Rate Values</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>AUC: Area Under the ROC Curve</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.bootstrapping">
<span class="sig-name descname"><span class="pre">bootstrapping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.bootstrapping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.bootstrapping" title="Permalink to this definition"></a></dt>
<dd><p>Computes ROC AUC variance for a single set of predictions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>ground_truth: np.array of 0 and 1
predictions: np.array of floats of the probability of being class 1</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.calc_pvalue">
<span class="sig-name descname"><span class="pre">calc_pvalue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aucs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.calc_pvalue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.calc_pvalue" title="Permalink to this definition"></a></dt>
<dd><p>Computes log(10) of p-values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>aucs: 1D array of AUCs
sigma: AUC DeLong covariances</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log10(pvalue)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.ci_">
<span class="sig-name descname"><span class="pre">ci_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.ci_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.ci_" title="Permalink to this definition"></a></dt>
<dd><p>Estimates confidence interval for Bernoulli p</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>tp: number of positive outcomes, TP in this case
n: number of attemps, TP+FP for Precision, TP+FN for Recall
alpha: confidence level</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple[float, float]: lower and upper bounds of the confidence interval</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.compute_ground_truth_statistics">
<span class="sig-name descname"><span class="pre">compute_ground_truth_statistics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.compute_ground_truth_statistics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.compute_ground_truth_statistics" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.compute_midrank">
<span class="sig-name descname"><span class="pre">compute_midrank</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.compute_midrank"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.compute_midrank" title="Permalink to this definition"></a></dt>
<dd><p>Computes midranks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>x - a 1D numpy array</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>array of midranks</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.compute_midrank_weight">
<span class="sig-name descname"><span class="pre">compute_midrank_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.compute_midrank_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.compute_midrank_weight" title="Permalink to this definition"></a></dt>
<dd><p>Computes midranks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>x - a 1D numpy array</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>array of midranks</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.delong_roc_variance">
<span class="sig-name descname"><span class="pre">delong_roc_variance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.delong_roc_variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.delong_roc_variance" title="Permalink to this definition"></a></dt>
<dd><p>Computes ROC AUC variance for a single set of predictions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>ground_truth: np.array of 0 and 1
predictions: np.array of floats of the probability of being class 1</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.fastDeLong">
<span class="sig-name descname"><span class="pre">fastDeLong</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions_sorted_transposed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_1_count</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.fastDeLong"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.fastDeLong" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.fastDeLong_no_weights">
<span class="sig-name descname"><span class="pre">fastDeLong_no_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions_sorted_transposed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_1_count</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.fastDeLong_no_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.fastDeLong_no_weights" title="Permalink to this definition"></a></dt>
<dd><p>The fast version of DeLong’s method for computing the covariance of
unadjusted AUC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt>predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]</dt><dd><p>sorted such as the examples with label “1” are first</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(AUC value, DeLong covariance)</p>
</dd>
</dl>
<dl>
<dt>Reference:</dt><dd><dl class="simple">
<dt>&#64;article{sun2014fast,</dt><dd><p>title={Fast Implementation of DeLong’s Algorithm for Comparing the Areas Under Correlated Receiver Oerating Characteristic Curves},
author={Xu Sun and Weichao Xu},
journal={IEEE Signal Processing Letters},
volume={21},
number={11},
pages={1389–1393},
year={2014},
publisher={IEEE}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.fastDeLong_weights">
<span class="sig-name descname"><span class="pre">fastDeLong_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions_sorted_transposed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_1_count</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.fastDeLong_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.fastDeLong_weights" title="Permalink to this definition"></a></dt>
<dd><p>The fast version of DeLong’s method for computing the covariance of
unadjusted AUC.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt>predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]</dt><dd><p>sorted such as the examples with label “1” are first</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(AUC value, DeLong covariance)</p>
</dd>
<dt class="field-odd">Reference</dt>
<dd class="field-odd"><dl class="simple">
<dt>&#64;article{sun2014fast,</dt><dd><p>title={Fast Implementation of DeLong’s Algorithm for Comparing the Areas Under Correlated Receiver Oerating Characteristic Curves},
author={Xu Sun and Weichao Xu},
journal={IEEE Signal Processing Letters},
volume={21},
number={11},
pages={1389–1393},
year={2014},
publisher={IEEE}</p>
</dd>
</dl>
<p>}</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="assessment.uncertainty.Uncertainty_Analysis.get_report">
<span class="sig-name descname"><span class="pre">get_report</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_truth</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/assessment/uncertainty.html#Uncertainty_Analysis.get_report"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#assessment.uncertainty.Uncertainty_Analysis.get_report" title="Permalink to this definition"></a></dt>
<dd><p>This method recieve the machine learning prediction output and the ground truth and report several metrics. This is the main metod of the Uncertainty_Analysis class which calls other methods to procude results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p>y_truth: ground_truth -  np.array of 0 and 1
y_pred:  predictions - np.array of floats of the probability of being class 1</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>precision
Precision Conficenc Interval
Recall
Recall Conficenc Interval
AUC based on delong method and its Conficenc Interval and COV 
False Positive Rate
True Positive Rate
AUC
Confusion Matrix</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="about-this-module">
<h2>About this module<a class="headerlink" href="#about-this-module" title="Permalink to this heading"></a></h2>
<p>This demonstration guides you through the process of using ValidPath to for performance evaluation of ML models. This is enabled using the get_report method of the UncertaintyAnalysis class in the ValidPath. The input to this method are the probability results of the ML model as well as the truth values. The output of this method include:</p>
<blockquote>
<div><p>Confusion Matrix</p>
</div></blockquote>
<a class="reference internal image-reference" href="_images/assessment6.PNG"><img alt="_images/assessment6.PNG" class="align-center" src="_images/assessment6.PNG" style="width: 300px;" /></a>
<p>For the confidence interval calculation, we first define J=  TP/(TP+FN+FP) , and computed its 95% CI [JL, JU] based on the binomial distribution. Then because F1=  2J/(1+J) , the 95% CI of F1 is [2JL/(1+JL), 2JU/(1+JU)].</p>
</section>
<section id="loading-required-packages">
<h2>Loading Required Packages<a class="headerlink" href="#loading-required-packages" title="Permalink to this heading"></a></h2>
<p>This step involves importing various Python modules that are needed for our analysis.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">import numpy as np</span>
<span class="go">import pandas as pd</span>
<span class="go">from assessment.uncertainty import Uncertainty_Analysis</span>
<span class="go">UncertaintyAnalysis = Uncertainty_Analysis()</span>
</pre></div>
</div>
</section>
<section id="generate-results">
<h2>Generate Results<a class="headerlink" href="#generate-results" title="Permalink to this heading"></a></h2>
<p>Having the output of the binary classification results, we can now generate the performance results. In order to generate the annotation files, we can use the get_report method of the UncertaintyAnalysis class.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">UncertaintyAnalysis. get_report(y_pred , y_truth) → Array</span>
<span class="go">Receive the classification probabilities and the truth and generate the results.</span>
<span class="go">Parameters:</span>
<span class="go">        y_pred (arr) – prediction results (probabilities)</span>
<span class="go">        y_truth (arr) – truth</span>
<span class="go">Returns:</span>
<span class="go">        Array – the classification report</span>
</pre></div>
</div>
<p>You can run the following code to generate classification report:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">import numpy as np</span>
<span class="go">import pandas as pd</span>
<span class="go">from assessment.uncertainty import Uncertainty_Analysis</span>
<span class="go">UncertaintyAnalysis = Uncertainty_Analysis()</span>
<span class="go">xls_file = &quot;C:/Results/ResultsExample.xlsx&quot;</span>
<span class="go">UncertaintyAnalysis.perform_Bootstrap= True</span>
<span class="go">UncertaintyAnalysis.plot_roc= True</span>
<span class="go">UncertaintyAnalysis.perform_Delong= True</span>
<span class="go">UncertaintyAnalysis.tag = “TEST”</span>
<span class="gp">#</span>loading file tnto dataframe
<span class="go">df = pd.read_excel(xls_file)</span>
<span class="gp">#</span>define two list to save values
<span class="go">y_pred=[]</span>
<span class="go">y_truth= []</span>
<span class="gp">#</span>extraction columns values
<span class="go">for i in df.values:</span>
<span class="go">        y_truth.append(i[0])</span>
<span class="go">        y_pred.append(i[1])</span>
<span class="gp">#</span>convert list to ndarray
<span class="go">y_pred = np.array(y_pred)</span>
<span class="go">y_truth = np.array(y_truth)</span>
<span class="go">Results = UncertaintyAnalysis.get_report(y_pred , y_truth)</span>
</pre></div>
</div>
<p>After running the code and provide the input data, you will see the performance report like the following:</p>
<a class="reference internal image-reference" href="_images/assessment7.PNG"><img alt="_images/assessment7.PNG" class="align-center" src="_images/assessment7.PNG" style="width: 300px;" /></a>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ann_generator.html" class="btn btn-neutral float-left" title="Annotation File Generator" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Seyed Kahaki.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>